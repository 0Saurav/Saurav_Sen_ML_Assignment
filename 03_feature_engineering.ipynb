{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5751bee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING FOR VULNERABILITY ANALYSIS - IMPROVED VERSION\n",
      "================================================================================\n",
      "\n",
      "1. Loading data...\n",
      "   ✓ Loaded 77 districts with 41 columns\n",
      "   District columns:  ID DISTRICT_NAME\n",
      " 14     Taplejung\n",
      " 15 Sankhuwasabha\n",
      " 16    Solukhumbu\n",
      "\n",
      "2. Identifying feature groups...\n",
      "   Walls: 8 features\n",
      "     Samples: WAL_MUD_BONDED_BRICKS_STONE, WAL_CEMENT_BONDED_BRICKS_STONE, WAL_WOOD_PLANKS...\n",
      "   Water: 9 features\n",
      "     Samples: DRI_TAP_PIPED_WITHIN_PREMISES, DRI_TAP_PIPED_OUTSIDE_PREMISES, DRI_TUBEWELL_HANDPUMP...\n",
      "   Toilets: 5 features\n",
      "     Samples: TOI_FLUSH_PUBLIC_SEWERAGE, TOI_FLUSH_SEPTIC_TANK, TOI_PIT_TOILET...\n",
      "\n",
      "3. Converting counts to percentages...\n",
      "   ✓ Created 8 percentage features for Walls\n",
      "   ✓ Created 9 percentage features for Water\n",
      "   ✓ Created 5 percentage features for Toilets\n",
      "   Total percentage features: 22\n",
      "\n",
      "4. Creating vulnerability indices (for target only)...\n",
      "   ✓ HOUSING_VULN: average of 5 features (TARGET ONLY)\n",
      "   ✓ WATER_VULN: average of 4 features (TARGET ONLY)\n",
      "   ✓ SANITATION_VULN: average of 2 features (TARGET ONLY)\n",
      "\n",
      "5. Creating additional engineered features for ML...\n",
      "   ✓ Created 5 engineered features for ML\n",
      "\n",
      "6. Creating overall vulnerability score (TARGET)...\n",
      "   ✓ Created vulnerability score (range: 2.4 - 21.8)\n",
      "   ✓ Normalized to 0-100 scale\n",
      "\n",
      "7. Creating vulnerability categories (TARGET)...\n",
      "   Category distribution:\n",
      "     Low: 20 districts (26.0%)\n",
      "     Medium: 19 districts (24.7%)\n",
      "     High: 19 districts (24.7%)\n",
      "     Very High: 19 districts (24.7%)\n",
      "\n",
      "   Most vulnerable districts:\n",
      "DISTRICT_NAME  VULNERABILITY_SCORE_NORM VULNERABILITY_CATEGORY\n",
      "        Humla                     100.0              Very High\n",
      "         Mugu                      97.3              Very High\n",
      "        Dolpa                      74.7              Very High\n",
      "\n",
      "   Least vulnerable districts:\n",
      "DISTRICT_NAME  VULNERABILITY_SCORE_NORM VULNERABILITY_CATEGORY\n",
      "    Kathmandu                       0.0                    Low\n",
      "    Bhaktapur                       2.1                    Low\n",
      "        Kaski                       3.2                    Low\n",
      "\n",
      "8. Preparing ML dataset (separating features from target)...\n",
      "   Raw percentage features: 22\n",
      "   Engineered ML features: 5\n",
      "   Vulnerability indices (EXCLUDED from features to avoid data leakage): 3\n",
      "   Total ML features: 27\n",
      "   ✓ Added target variables: TARGET_CATEGORY and TARGET_SCORE\n",
      "\n",
      "   Feature groups summary:\n",
      "     - Raw percentages: 22 features\n",
      "     - Engineered ratios: 5 features\n",
      "     - Categorical: 0 features\n",
      "     - TOTAL for ML: 27 features\n",
      "\n",
      "   Sample features from each group:\n",
      "     Raw PCT features: PCT_WAL_MUD_BONDED_BRICKS_STONE, PCT_WAL_CEMENT_BONDED_BRICKS_STONE, PCT_WAL_WOOD_PLANKS...\n",
      "     Engineered features: WALL_QUALITY_RATIO, WATER_ACCESS_RATIO, SANITATION_RATIO, WALL_DIVERSITY, WATER_SOURCE_DIVERSITY\n",
      "\n",
      "9. Saving outputs...\n",
      "   ✓ Full dataset: C:\\Users\\saurav\\Downloads\\SEVI_Nepal_Project\\data\\final\\nepal_districts_engineered.csv\n",
      "   ✓ ML dataset: C:\\Users\\saurav\\Downloads\\SEVI_Nepal_Project\\data\\final\\nepal_districts_ml_ready.csv\n",
      "   ✓ Feature documentation: C:\\Users\\saurav\\Downloads\\SEVI_Nepal_Project\\data\\final\\feature_documentation.txt\n",
      "\n",
      "10. Creating visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurav\\AppData\\Local\\Temp\\ipykernel_1460\\4224510854.py:418: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  box = axes[1].boxplot(box_data, labels=category_order, patch_artist=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Created 4 visualization sets in results/figures/\n",
      "\n",
      "================================================================================\n",
      "FEATURE ENGINEERING COMPLETE - IMPROVED VERSION\n",
      "================================================================================\n",
      "\n",
      "SUMMARY:\n",
      "• Districts processed: 77\n",
      "• Raw percentage features: 22\n",
      "• Engineered ML features: 5\n",
      "• Categorical features: 0\n",
      "• TOTAL ML features: 27\n",
      "• Target variable created: True\n",
      "\n",
      "DATA LEAKAGE PREVENTION:\n",
      "• Excluded from ML features: 3 vulnerability indices\n",
      "• Target created from: HOUSING_VULN, WATER_VULN, SANITATION_VULN\n",
      "• ML features are independent of target construction\n",
      "\n",
      "DATASETS SAVED:\n",
      "1. nepal_districts_engineered.csv - All engineered features and targets\n",
      "2. nepal_districts_ml_ready.csv - Clean dataset for ML (features + target)\n",
      "3. feature_documentation.txt - Detailed feature descriptions\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS FOR ML MODELING:\n",
      "================================================================================\n",
      "1. Data preprocessing:\n",
      "   • One-hot encode PROVINCE (if included)\n",
      "   • Scale numerical features\n",
      "   • Check for multicollinearity\n",
      "\n",
      "2. Classification modeling:\n",
      "   • Use TARGET_CATEGORY as y (categorical)\n",
      "   • Use all_ml_features as X\n",
      "   • Apply proper cross-validation\n",
      "\n",
      "3. Regression modeling (optional):\n",
      "   • Use TARGET_SCORE as y (continuous)\n",
      "   • Predict vulnerability scores\n",
      "\n",
      "Your data is now properly prepared for machine learning without data leakage!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nepal District Vulnerability Analysis - Feature Engineering\n",
    "Step 3: Create features and target variable for ML analysis\n",
    "Improved Version: Fixed data leakage issues and enhanced feature engineering\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Setup paths\n",
    "BASE_PATH = Path(r'C:\\Users\\saurav\\Downloads\\SEVI_Nepal_Project')\n",
    "PROCESSED_PATH = BASE_PATH / 'data' / 'processed'\n",
    "FINAL_PATH = BASE_PATH / 'data' / 'final'\n",
    "VIS_PATH = BASE_PATH / 'results' / 'figures'\n",
    "\n",
    "# Create directories\n",
    "for path in [FINAL_PATH, VIS_PATH]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING FOR VULNERABILITY ANALYSIS - IMPROVED VERSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load cleaned data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Loading data...\")\n",
    "df = pd.read_csv(PROCESSED_PATH / 'simple_merged_districts.csv')\n",
    "print(f\"   ✓ Loaded {len(df)} districts with {len(df.columns)} columns\")\n",
    "print(f\"   District columns: {df[['ID', 'DISTRICT_NAME']].head(3).to_string(index=False)}\")\n",
    "\n",
    "# Check for province data\n",
    "if 'PROVINCE' in df.columns:\n",
    "    print(f\"   ✓ Province data available: {df['PROVINCE'].nunique()} provinces\")\n",
    "    print(f\"   Province distribution:\\n{df['PROVINCE'].value_counts().sort_index()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Identify feature groups\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Identifying feature groups...\")\n",
    "\n",
    "# Group features by type\n",
    "feature_groups = {\n",
    "    'Walls': [col for col in df.columns if col.startswith('WAL_')],\n",
    "    'Water': [col for col in df.columns if col.startswith('DRI_')],\n",
    "    'Toilets': [col for col in df.columns if col.startswith('TOI_')]\n",
    "}\n",
    "\n",
    "for group_name, features in feature_groups.items():\n",
    "    if features:\n",
    "        print(f\"   {group_name}: {len(features)} features\")\n",
    "        print(f\"     Samples: {', '.join(features[:3])}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Convert counts to percentages\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Converting counts to percentages...\")\n",
    "\n",
    "def safe_percentage(df, count_features):\n",
    "    \"\"\"Safely convert counts to percentages\"\"\"\n",
    "    total = df[count_features].sum(axis=1)\n",
    "    # Replace zeros with NaN to avoid division by zero\n",
    "    total = total.replace(0, np.nan)\n",
    "    \n",
    "    percentages = df[count_features].div(total, axis=0) * 100\n",
    "    # Fill NaN values with 0 (for districts with no data in a category)\n",
    "    percentages = percentages.fillna(0)\n",
    "    \n",
    "    # Rename columns\n",
    "    percentages.columns = [f'PCT_{col}' for col in count_features]\n",
    "    \n",
    "    return percentages\n",
    "\n",
    "# Create percentage features\n",
    "pct_df = pd.DataFrame()\n",
    "for group_name, features in feature_groups.items():\n",
    "    if features:  # Check if list is not empty\n",
    "        group_pct = safe_percentage(df, features)\n",
    "        pct_df = pd.concat([pct_df, group_pct], axis=1)\n",
    "        print(f\"   ✓ Created {len(features)} percentage features for {group_name}\")\n",
    "\n",
    "# Combine with original data\n",
    "df_pct = pd.concat([df[['ID', 'DISTRICT_NAME']], pct_df], axis=1)\n",
    "print(f\"   Total percentage features: {len(pct_df.columns)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create vulnerability indices (for target creation ONLY)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Creating vulnerability indices (for target only)...\")\n",
    "\n",
    "# Define vulnerable materials/sources - USED ONLY FOR TARGET CREATION\n",
    "vuln_mapping = {\n",
    "    # Housing vulnerability (poor quality materials)\n",
    "    'HOUSING_VULN': [\n",
    "        'PCT_WAL_MUD_BONDED_BRICKS_STONE',\n",
    "        'PCT_WAL_BAMBOO',\n",
    "        'PCT_WAL_UNBAKED_BRICKS',\n",
    "        'PCT_WAL_GALVANIZED_SHEET',\n",
    "        'PCT_WAL_OTHER'\n",
    "    ],\n",
    "    \n",
    "    # Water vulnerability (unsafe sources)\n",
    "    'WATER_VULN': [\n",
    "        'PCT_DRI_UNCOVERED_WELL_KUWA',\n",
    "        'PCT_DRI_SPOUT_WATER',\n",
    "        'PCT_DRI_RIVER_STREAM',\n",
    "        'PCT_DRI_OTHER_SOURCES'\n",
    "    ],\n",
    "    \n",
    "    # Sanitation vulnerability (poor facilities)\n",
    "    'SANITATION_VULN': [\n",
    "        'PCT_TOI_PIT_TOILET',\n",
    "        'PCT_TOI_WITHOUT_TOILET_FACILITY'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Calculate indices for TARGET ONLY\n",
    "vuln_indices_target = pd.DataFrame()\n",
    "for index_name, features in vuln_mapping.items():\n",
    "    # Use only features that exist in our data\n",
    "    existing_features = [f for f in features if f in df_pct.columns]\n",
    "    if existing_features:\n",
    "        vuln_indices_target[index_name] = df_pct[existing_features].mean(axis=1)\n",
    "        print(f\"   ✓ {index_name}: average of {len(existing_features)} features (TARGET ONLY)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Create additional engineered features (for ML features)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Creating additional engineered features for ML...\")\n",
    "\n",
    "# Create ratio-based features that are informative but not directly used in target\n",
    "engineered_features = {}\n",
    "\n",
    "# 1. Infrastructure quality ratios\n",
    "# Safe vs unsafe walls ratio\n",
    "if 'PCT_WAL_CEMENT_BONDED_BRICKS_STONE' in df_pct.columns:\n",
    "    safe_walls = df_pct['PCT_WAL_CEMENT_BONDED_BRICKS_STONE'].fillna(0)\n",
    "    unsafe_walls = df_pct.get('PCT_WAL_MUD_BONDED_BRICKS_STONE', 0).fillna(0) + \\\n",
    "                   df_pct.get('PCT_WAL_UNBAKED_BRICKS', 0).fillna(0)\n",
    "    engineered_features['WALL_QUALITY_RATIO'] = (safe_walls + 1) / (unsafe_walls + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# 2. Water access quality\n",
    "safe_water_features = []\n",
    "unsafe_water_features = []\n",
    "\n",
    "for feat in df_pct.columns:\n",
    "    if 'PCT_DRI_' in feat:\n",
    "        if any(term in feat for term in ['TAP_PIPED', 'TUBEWELL', 'COVERED_WELL']):\n",
    "            safe_water_features.append(feat)\n",
    "        elif any(term in feat for term in ['UNCOVERED', 'RIVER', 'OTHER']):\n",
    "            unsafe_water_features.append(feat)\n",
    "\n",
    "safe_water = df_pct[safe_water_features].sum(axis=1).fillna(0) if safe_water_features else 0\n",
    "unsafe_water = df_pct[unsafe_water_features].sum(axis=1).fillna(0) if unsafe_water_features else 0\n",
    "engineered_features['WATER_ACCESS_RATIO'] = (safe_water + 1) / (unsafe_water + 1)\n",
    "\n",
    "# 3. Sanitation access\n",
    "if 'PCT_TOI_FLUSH_PUBLIC_SEWERAGE' in df_pct.columns:\n",
    "    good_sanitation = df_pct['PCT_TOI_FLUSH_PUBLIC_SEWERAGE'].fillna(0) + \\\n",
    "                      df_pct.get('PCT_TOI_FLUSH_SEPTIC_TANK', 0).fillna(0)\n",
    "    poor_sanitation = df_pct.get('PCT_TOI_WITHOUT_TOILET_FACILITY', 0).fillna(0)\n",
    "    engineered_features['SANITATION_RATIO'] = (good_sanitation + 1) / (poor_sanitation + 1)\n",
    "\n",
    "# 4. Diversity indices (Simpson's Diversity Index)\n",
    "def simpson_diversity(series):\n",
    "    \"\"\"Calculate Simpson's Diversity Index for percentage data\"\"\"\n",
    "    proportions = series / 100\n",
    "    return 1 - (proportions ** 2).sum()\n",
    "\n",
    "# Wall material diversity\n",
    "wall_features = [col for col in df_pct.columns if 'PCT_WAL_' in col]\n",
    "if wall_features:\n",
    "    engineered_features['WALL_DIVERSITY'] = df_pct[wall_features].apply(simpson_diversity, axis=1)\n",
    "\n",
    "# Water source diversity\n",
    "water_features = [col for col in df_pct.columns if 'PCT_DRI_' in col]\n",
    "if water_features:\n",
    "    engineered_features['WATER_SOURCE_DIVERSITY'] = df_pct[water_features].apply(simpson_diversity, axis=1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "engineered_df = pd.DataFrame(engineered_features)\n",
    "print(f\"   ✓ Created {len(engineered_features)} engineered features for ML\")\n",
    "\n",
    "# Combine all features\n",
    "df_engineered = pd.concat([df_pct, engineered_df], axis=1)\n",
    "\n",
    "# Add province information if available\n",
    "if 'PROVINCE' in df.columns:\n",
    "    df_engineered['PROVINCE'] = df['PROVINCE']\n",
    "    print(f\"   ✓ Added province information\")\n",
    "\n",
    "# Add vulnerability indices (FOR TARGET ONLY - will be separated later)\n",
    "df_engineered = pd.concat([df_engineered, vuln_indices_target], axis=1)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Create overall vulnerability score (TARGET)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. Creating overall vulnerability score (TARGET)...\")\n",
    "\n",
    "# Weighted average of vulnerability components (this is our target)\n",
    "weights = {\n",
    "    'HOUSING_VULN': 0.4,      # Housing is often most important\n",
    "    'WATER_VULN': 0.3,        # Water access is critical\n",
    "    'SANITATION_VULN': 0.3     # Sanitation affects health\n",
    "}\n",
    "\n",
    "# Calculate weighted score (TARGET VARIABLE)\n",
    "vulnerability_components = []\n",
    "for index, weight in weights.items():\n",
    "    if index in df_engineered.columns:\n",
    "        vulnerability_components.append(df_engineered[index] * weight)\n",
    "\n",
    "if vulnerability_components:\n",
    "    df_engineered['VULNERABILITY_SCORE'] = sum(vulnerability_components)\n",
    "    \n",
    "    # Normalize to 0-100 scale for easier interpretation\n",
    "    min_score = df_engineered['VULNERABILITY_SCORE'].min()\n",
    "    max_score = df_engineered['VULNERABILITY_SCORE'].max()\n",
    "    if max_score > min_score:  # Avoid division by zero\n",
    "        df_engineered['VULNERABILITY_SCORE_NORM'] = (\n",
    "            (df_engineered['VULNERABILITY_SCORE'] - min_score) / \n",
    "            (max_score - min_score) * 100\n",
    "        )\n",
    "    else:\n",
    "        df_engineered['VULNERABILITY_SCORE_NORM'] = 50  # Default mid-point\n",
    "        \n",
    "    print(f\"   ✓ Created vulnerability score (range: {min_score:.1f} - {max_score:.1f})\")\n",
    "    print(f\"   ✓ Normalized to 0-100 scale\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Create target categories (TARGET)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n7. Creating vulnerability categories (TARGET)...\")\n",
    "\n",
    "if 'VULNERABILITY_SCORE_NORM' in df_engineered.columns:\n",
    "    # Create 4 categories using quartiles\n",
    "    df_engineered['VULNERABILITY_CATEGORY'] = pd.qcut(\n",
    "        df_engineered['VULNERABILITY_SCORE_NORM'],\n",
    "        q=4,\n",
    "        labels=['Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    "    \n",
    "    # Show distribution\n",
    "    print(\"   Category distribution:\")\n",
    "    category_counts = df_engineered['VULNERABILITY_CATEGORY'].value_counts().sort_index()\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df_engineered)) * 100\n",
    "        print(f\"     {category}: {count} districts ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Show extremes\n",
    "    print(\"\\n   Most vulnerable districts:\")\n",
    "    top_3 = df_engineered.nlargest(3, 'VULNERABILITY_SCORE_NORM')[['DISTRICT_NAME', 'VULNERABILITY_SCORE_NORM', 'VULNERABILITY_CATEGORY']].copy()\n",
    "    top_3['VULNERABILITY_SCORE_NORM'] = top_3['VULNERABILITY_SCORE_NORM'].round(1)\n",
    "    print(top_3.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n   Least vulnerable districts:\")\n",
    "    bottom_3 = df_engineered.nsmallest(3, 'VULNERABILITY_SCORE_NORM')[['DISTRICT_NAME', 'VULNERABILITY_SCORE_NORM', 'VULNERABILITY_CATEGORY']].copy()\n",
    "    bottom_3['VULNERABILITY_SCORE_NORM'] = bottom_3['VULNERABILITY_SCORE_NORM'].round(1)\n",
    "    print(bottom_3.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Prepare ML dataset (SEPARATE FEATURES FROM TARGET)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n8. Preparing ML dataset (separating features from target)...\")\n",
    "\n",
    "# IDENTIFY FEATURE TYPES:\n",
    "\n",
    "# 1. Raw percentage features (PCT_* but NOT _VULN indices)\n",
    "raw_pct_features = [col for col in df_engineered.columns \n",
    "                    if col.startswith('PCT_') and not col.endswith('_VULN')]\n",
    "\n",
    "print(f\"   Raw percentage features: {len(raw_pct_features)}\")\n",
    "\n",
    "# 2. Engineered features (ratios, diversity indices)\n",
    "engineered_ml_features = [col for col in df_engineered.columns \n",
    "                          if col in engineered_features.keys()]\n",
    "\n",
    "print(f\"   Engineered ML features: {len(engineered_ml_features)}\")\n",
    "\n",
    "# 3. Categorical features (for one-hot encoding later)\n",
    "categorical_features = []\n",
    "if 'PROVINCE' in df_engineered.columns:\n",
    "    categorical_features = ['PROVINCE']\n",
    "    print(f\"   Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# 4. VULNERABILITY INDICES - THESE ARE TARGET-RELATED, NOT FEATURES!\n",
    "# DO NOT INCLUDE THESE IN ML FEATURES TO AVOID DATA LEAKAGE\n",
    "vuln_indices = [col for col in df_engineered.columns if col.endswith('_VULN')]\n",
    "print(f\"   Vulnerability indices (EXCLUDED from features to avoid data leakage): {len(vuln_indices)}\")\n",
    "\n",
    "# Combine ALL features (excluding target-related indices)\n",
    "all_ml_features = raw_pct_features + engineered_ml_features + categorical_features\n",
    "print(f\"   Total ML features: {len(all_ml_features)}\")\n",
    "\n",
    "# Create ML dataset\n",
    "ml_df = df_engineered[['ID', 'DISTRICT_NAME'] + all_ml_features].copy()\n",
    "\n",
    "# Add target variables\n",
    "if 'VULNERABILITY_CATEGORY' in df_engineered.columns:\n",
    "    ml_df['TARGET_CATEGORY'] = df_engineered['VULNERABILITY_CATEGORY']\n",
    "    ml_df['TARGET_SCORE'] = df_engineered['VULNERABILITY_SCORE_NORM']\n",
    "    print(f\"   ✓ Added target variables: TARGET_CATEGORY and TARGET_SCORE\")\n",
    "\n",
    "# Display feature information\n",
    "print(f\"\\n   Feature groups summary:\")\n",
    "print(f\"     - Raw percentages: {len(raw_pct_features)} features\")\n",
    "print(f\"     - Engineered ratios: {len(engineered_ml_features)} features\")\n",
    "print(f\"     - Categorical: {len(categorical_features)} features\")\n",
    "print(f\"     - TOTAL for ML: {len(all_ml_features)} features\")\n",
    "\n",
    "print(f\"\\n   Sample features from each group:\")\n",
    "print(f\"     Raw PCT features: {', '.join(raw_pct_features[:3])}...\")\n",
    "if engineered_ml_features:\n",
    "    print(f\"     Engineered features: {', '.join(engineered_ml_features)}\")\n",
    "if categorical_features:\n",
    "    print(f\"     Categorical features: {', '.join(categorical_features)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Save outputs\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n9. Saving outputs...\")\n",
    "\n",
    "# Save full engineered dataset\n",
    "df_engineered.to_csv(FINAL_PATH / 'nepal_districts_engineered.csv', index=False)\n",
    "print(f\"   ✓ Full dataset: {FINAL_PATH / 'nepal_districts_engineered.csv'}\")\n",
    "\n",
    "# Save ML-ready dataset\n",
    "ml_df.to_csv(FINAL_PATH / 'nepal_districts_ml_ready.csv', index=False)\n",
    "print(f\"   ✓ ML dataset: {FINAL_PATH / 'nepal_districts_ml_ready.csv'}\")\n",
    "\n",
    "# Save detailed feature documentation\n",
    "with open(FINAL_PATH / 'feature_documentation.txt', 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"FEATURE DOCUMENTATION FOR NEPAL VULNERABILITY ANALYSIS\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"1. RAW PERCENTAGE FEATURES\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(f\"Total: {len(raw_pct_features)}\\n\\n\")\n",
    "    for feat in sorted(raw_pct_features):\n",
    "        f.write(f\"  • {feat}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n2. ENGINEERED FEATURES\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(f\"Total: {len(engineered_ml_features)}\\n\\n\")\n",
    "    for feat in engineered_ml_features:\n",
    "        f.write(f\"  • {feat}\\n\")\n",
    "        # Add description\n",
    "        if 'RATIO' in feat:\n",
    "            f.write(f\"    Ratio of good quality to poor quality\\n\")\n",
    "        elif 'DIVERSITY' in feat:\n",
    "            f.write(f\"    Simpson's Diversity Index (higher = more diverse)\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n3. CATEGORICAL FEATURES\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(f\"Total: {len(categorical_features)}\\n\\n\")\n",
    "    for feat in categorical_features:\n",
    "        f.write(f\"  • {feat}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n4. TARGET VARIABLES (NOT FEATURES!)\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(\"  • TARGET_CATEGORY: Vulnerability category (Low, Medium, High, Very High)\\n\")\n",
    "    f.write(\"  • TARGET_SCORE: Normalized vulnerability score (0-100)\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n5. EXCLUDED VARIABLES (to avoid data leakage)\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    for feat in vuln_indices:\n",
    "        f.write(f\"  • {feat} (used to create target, excluded from features)\\n\")\n",
    "\n",
    "print(f\"   ✓ Feature documentation: {FINAL_PATH / 'feature_documentation.txt'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: Create visualizations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n10. Creating visualizations...\")\n",
    "\n",
    "try:\n",
    "    # Set style\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # 1. Score distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(df_engineered['VULNERABILITY_SCORE_NORM'], bins=15, \n",
    "                 edgecolor='black', alpha=0.7, color='skyblue', density=True)\n",
    "    axes[0].set_title('District Vulnerability Score Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Vulnerability Score (0-100)', fontsize=12)\n",
    "    axes[0].set_ylabel('Density', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    mean_score = df_engineered['VULNERABILITY_SCORE_NORM'].mean()\n",
    "    median_score = df_engineered['VULNERABILITY_SCORE_NORM'].median()\n",
    "    axes[0].axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_score:.1f}')\n",
    "    axes[0].axvline(median_score, color='green', linestyle='--', linewidth=2, label=f'Median: {median_score:.1f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Boxplot by category\n",
    "    category_order = ['Low', 'Medium', 'High', 'Very High']\n",
    "    box_data = [df_engineered[df_engineered['VULNERABILITY_CATEGORY'] == cat]['VULNERABILITY_SCORE_NORM'] \n",
    "                for cat in category_order]\n",
    "    \n",
    "    box = axes[1].boxplot(box_data, labels=category_order, patch_artist=True)\n",
    "    colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    axes[1].set_title('Vulnerability Score by Category', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Category', fontsize=12)\n",
    "    axes[1].set_ylabel('Vulnerability Score', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VIS_PATH / 'vulnerability_distribution_boxplot.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    # 2. Category bar chart with province breakdown\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    if 'PROVINCE' in df_engineered.columns:\n",
    "        # Create cross-tabulation\n",
    "        cross_tab = pd.crosstab(df_engineered['PROVINCE'], df_engineered['VULNERABILITY_CATEGORY'])\n",
    "        cross_tab = cross_tab[category_order]  # Ensure order\n",
    "        \n",
    "        ax = cross_tab.plot(kind='bar', stacked=True, color=colors, \n",
    "                            edgecolor='black', linewidth=0.5, figsize=(12, 8))\n",
    "        \n",
    "        plt.title('Vulnerability Categories by Province', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Province', fontsize=12)\n",
    "        plt.ylabel('Number of Districts', fontsize=12)\n",
    "        plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add total counts on top of each bar\n",
    "        for i, (province, row) in enumerate(cross_tab.iterrows()):\n",
    "            total = row.sum()\n",
    "            plt.text(i, total + 0.5, str(total), ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        # Simple bar chart if no province data\n",
    "        category_counts = df_engineered['VULNERABILITY_CATEGORY'].value_counts().reindex(category_order)\n",
    "        bars = plt.bar(category_counts.index, category_counts.values, \n",
    "                       color=colors, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        plt.title('District Vulnerability Categories', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Category', fontsize=12)\n",
    "        plt.ylabel('Number of Districts', fontsize=12)\n",
    "        \n",
    "        # Add labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(VIS_PATH / 'vulnerability_categories_province.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    # 3. Correlation heatmap of engineered features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Select features for correlation\n",
    "    corr_features = engineered_ml_features + ['VULNERABILITY_SCORE_NORM']\n",
    "    corr_data = df_engineered[corr_features].corr()\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_data, dtype=bool))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(corr_data, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "                annot_kws={\"size\": 9})\n",
    "    \n",
    "    plt.title('Correlation: Engineered Features vs Vulnerability Score', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VIS_PATH / 'engineered_features_correlation.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    # 4. Scatter plot: Vulnerability vs Key Features\n",
    "    if engineered_ml_features:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        key_features = engineered_ml_features[:4]  # Plot first 4 engineered features\n",
    "        \n",
    "        for i, feature in enumerate(key_features):\n",
    "            if i < len(axes):\n",
    "                ax = axes[i]\n",
    "                ax.scatter(df_engineered[feature], df_engineered['VULNERABILITY_SCORE_NORM'],\n",
    "                          alpha=0.6, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "                \n",
    "                # Add trend line\n",
    "                z = np.polyfit(df_engineered[feature], df_engineered['VULNERABILITY_SCORE_NORM'], 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax.plot(df_engineered[feature], p(df_engineered[feature]), \n",
    "                       \"r--\", alpha=0.8, linewidth=2)\n",
    "                \n",
    "                # Calculate correlation\n",
    "                corr = df_engineered[feature].corr(df_engineered['VULNERABILITY_SCORE_NORM'])\n",
    "                ax.set_title(f'{feature}\\nCorrelation: {corr:.3f}', fontsize=11)\n",
    "                ax.set_xlabel(feature, fontsize=10)\n",
    "                ax.set_ylabel('Vulnerability Score', fontsize=10)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Vulnerability Score vs Engineered Features', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(VIS_PATH / 'vulnerability_vs_features.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.close('all')\n",
    "    print(\"   ✓ Created 4 visualization sets in results/figures/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ⚠ Visualization error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING COMPLETE - IMPROVED VERSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"• Districts processed: {len(df_engineered)}\")\n",
    "print(f\"• Raw percentage features: {len(raw_pct_features)}\")\n",
    "print(f\"• Engineered ML features: {len(engineered_ml_features)}\")\n",
    "print(f\"• Categorical features: {len(categorical_features)}\")\n",
    "print(f\"• TOTAL ML features: {len(all_ml_features)}\")\n",
    "print(f\"• Target variable created: {'VULNERABILITY_CATEGORY' in df_engineered.columns}\")\n",
    "\n",
    "print(f\"\\nDATA LEAKAGE PREVENTION:\")\n",
    "print(f\"• Excluded from ML features: {len(vuln_indices)} vulnerability indices\")\n",
    "print(f\"• Target created from: {', '.join(vuln_indices)}\")\n",
    "print(f\"• ML features are independent of target construction\")\n",
    "\n",
    "print(f\"\\nDATASETS SAVED:\")\n",
    "print(f\"1. nepal_districts_engineered.csv - All engineered features and targets\")\n",
    "print(f\"2. nepal_districts_ml_ready.csv - Clean dataset for ML (features + target)\")\n",
    "print(f\"3. feature_documentation.txt - Detailed feature descriptions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS FOR ML MODELING:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Data preprocessing:\")\n",
    "print(\"   • One-hot encode PROVINCE (if included)\")\n",
    "print(\"   • Scale numerical features\")\n",
    "print(\"   • Check for multicollinearity\")\n",
    "print(\"\\n2. Classification modeling:\")\n",
    "print(\"   • Use TARGET_CATEGORY as y (categorical)\")\n",
    "print(\"   • Use all_ml_features as X\")\n",
    "print(\"   • Apply proper cross-validation\")\n",
    "print(\"\\n3. Regression modeling (optional):\")\n",
    "print(\"   • Use TARGET_SCORE as y (continuous)\")\n",
    "print(\"   • Predict vulnerability scores\")\n",
    "\n",
    "print(\"\\nYour data is now properly prepared for machine learning without data leakage!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
